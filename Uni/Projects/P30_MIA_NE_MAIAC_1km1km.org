#+TITLE: MIA_NE_MAIAC_PM

* 0.Code run order
  :PROPERTIES:
  :ID:       b967025d-dec5-468a-afa4-2922cc2532da
  :END:

** 1.Extract AOD from HDF-Matlab code
run the matlab code located here
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn001_MATLAB_code
using the main launcher file
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn001_MATLAB_code/AOD_Importnew.m

$Note$ the launcher files just sources other matlab scripts that are in the same code dir 

to extract the RAW hdf files from MODIS/MAIAC into seperate text files per year per grid cell
see [[file:~/org/files/Uni/Guides/matlab.org::*Run%20code%20MIAC%20PM%20data%20(hdf%20lat/long%20files)][Run code MIAC PM data (hdf lat/long files)]] for more info on how to actually run the code

** 2.Build AOD datasets from txt files
run file:/home/zeltak/org/files/Uni/Projects/code/P31/cn002_allgridsfromtxt.sas
to extract the txt files from matlab output to sas datasets. 
also in the code a unique id for each tile is created
** 3.Create the full grid based on the seperate tiles
run file:/home/zeltak/Dropbox/uni/~code/NE_MIA_PM/org/cn003_create_FULL_grid.sas
to create a full grid of the whole study area (the whole eastern usa)
** 4.pull in EPA and IMPROVE PM2.5 data
use script

file:/home/zeltak/org/files/Uni/Projects/code/P31/cn004_PM_Final.sas

to create a PM dataset for all years 

** 6. Create meterological database
using script file:/home/zeltak/org/files/Uni/Projects/code/P31/cn006_create_NCDC_data_2012.sas
we create full yearly met with 'continuous stations' (temp, windspeed etc) data sets for all periods and the MET grid (metID)
** 6.Import_NE_MIA
Here we subset the tiles to only the ones covering NE and MIA
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn006_Import_NE_MIA.sas
 
** 7.create guid
we use the unique grid lat/long to create a guid in GIS from 1 to n

the file is here:

f:\Uni\Projects\p031_MIAC_PM\3.Work\2.Gather_data\FN007_Key_tables\basegrid.csv
** 8.create full pm per year datasets
we try (as best as possbile) to create a full time series for every PM station borrwowing data from nearest stations when not avilable
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn008_create_mpm_No_miss.sas
** 15. create model files

this scripts add all the temporal/spatial variables to the model and creates mod 1 and mod 2 files

file:/home/zeltak/org/files/Uni/Projects/code/P31/cn0015_modfile_creation.R
** 16.run mod1 and mod2
this script runs mod1 , mod1CV and mod2 satges
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn0016_mod1_mod2_creation.R
** 17.calculate MPM
this script calculates the mean PM for each grid cell from closest K stations per day and then supplements missing data with mean PM calculated per region.
!$Note$-there will still be some obsv missing. these are way up north where there isant daily pm minitors!
** 20.run mod3
we use this script to run mod3
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn0020_m3_2003.r
$Note-the above script is the template, the actual scripts are run yearly, see here for yeat to year scirpts:$ 
file:/home/zeltak/org/files/Uni/Projects/code/P31/yearly_batches
** 24.calculte land use in 200m for monitors and grids
using the script we calculate the actuall LU fine terms for the whole grid set, each at a 200m resolution and create a LPMID
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn0024_lu200_calc.R
then in GIS we join the PM monitor stations to these closest LPMID so it gets all the LU fine LPM Variables
** 25.caluclate spatial tempral LPM for monitors
using the script we calculate the actuall spatial and temporal variables for all monitor stations and create a full yearly time series
file:/home/zeltak/org/files/Uni/Projects/code/P31/cn0025_luMON_ST.R
** 26.run stage 4
file:
* 1.Data info
** 1.PM data
*** Source
PM data is taken from our already made EPA/IMPROVE dataset
*** Create dataset
We used the previous PM datasets used in the prev NE/MIA 10x10 analysis
** 2.MODIS MAIAC data
*** 1.info
**** general
Data comes from the MIAIC project headed by Alexi and Yujie:
[[mailto:alexei.i.lyapustin@nasa.gov]]
[[mailto:yujie.wang-1@nasa.gov]]

Data is already proccesed and in the form of hdf Files data is located on the drobo:
file:y:\MIAC_USA\

**** Naming Scheme of Files
MODIS Naming Conventions

MODIS filenames (i.e., the local granule ID) follow a naming convention
which gives useful information regarding the specific product.
For example, the filename

MAIACAOT.h02v02.20122351705.hdf

indicates:

h02v02 indicates custom tile yujie created

2012-year/235-jul day/1705-time

*** 2.HDF to DBF
**** Convert using matlab
***** Extract in matlab to dbf
We had help from a Matlab programmer (mailto:andrea.padoan@unipd.it)
There are a series of scripts and functions that are run to get Txt file from the HDF files:
[[file:~/org/files/Uni/Guides/matlab.org::*Run%20code%20MIAC%20PM%20data%20(binary%20lat/long%20files)][Run code MIAC PM data (binary lat/long files)]]
when the script finishes its run you should have text files in the
output folder for each year, a seperate text file per year
** 3.MET variables
[[We used NCDC data from 2000-2012 and only kept stations with 90%
completion rate:
file:code/P30/create_NCDC_data_2012.sas]]

** 4.PBL
Was downloaded from NARR analysis
http://www.esrl.noaa.gov/psd/data/gridded/data.narr.monolevel.html
the format was Netcdf
we used a IDL script to convert it to txt. you need a special IDL
package

http://acmg.seas.harvard.edu/gamap/

** 5.NDVI
From the MODIS LST analysis
** 6.Land Cover 
National Land Cover Data (NLCD)2006
Single land uses extracted as individual rasters:
(Two letter abbreviations in bold created by Steven Melly and used in variable and file names)

Single land use
*Op* Value:21 Developed, Open Space - Includes areas with a mixture of some constructed materials, but mostly vegetation in the form of lawn grasses.  Impervious surfaces account for less than 20 percent of total cover.  These areas most commonly include large-lot single-family housing units, parks, golf courses, and vegetation planted in developed settings for recreation, erosion control, or aesthetic purposes.

*Ld* Value: 22 Developed, Low Intensity -Includes areas with a mixture of constructed materials and vegetation.  Impervious surfaces account for 20-49 percent of total cover.  These areas most commonly include single-family housing units.

*Md* Value: 23 Developed, Medium Intensity - Includes areas with a mixture of constructed materials and vegetation. Impervious surfaces account for 50-79 percent of the total cover.  These areas most commonly include single-family housing units.

*Hd*  Value: 24 Developed, High Intensity - Includes highly developed areas where people reside or work in high numbers. Examples include apartment complexes, row houses and commercial/industrial.  Impervious surfaces account for 80 to100 percent of the total cover.

*Df* Value: 41 Deciduous Forest  - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species shed foliage simultaneously in response to seasonal change.

*Ev*  Value: 42 Evergreen Forest - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75 percent of the tree species maintain their leaves all year. Canopy is never without green foliage. 

*Mf* Value: 43 Mixed Forest - Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. Neither deciduous nor evergreen species are greater than 75 percent of total tree cover.

*Sh* Value: 52 Shrub/Scrub - Areas dominated by shrubs; less than 5 meters tall with shrub canopy typically greater than 20% of total vegetation. This class includes true shrubs, young trees in an early successional stage or trees stunted from environmental conditions.

*Gr* Value: 71 Grassland/Herbaceous - Areas dominated by grammanoid or herbaceous vegetation, generally greater than 80% of total vegetation.  These areas are not subject to intensive management such as tilling, but can be utilized for grazing.

*Pa*  Value: 81 Pasture/Hay  - Areas of grasses, legumes, or grass-legume mixtures planted for livestock grazing or the production of seed or hay crops, typically on a perennial cycle. Pasture/hay vegetation accounts for greater than 20 percent of total vegetation.

*Cr* Value: 82 Cultivated Crops - Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20 percent of total vegetation. This class also includes all land being actively tilled.



NLCD 2006 30 m resolution rasters was reclassified as rasters for each of the individual land uses listed above.  In each raster cells with the specified land use were given the value 1 all other cells were set to 0

ArcGIS Focal statistics tool was used to sum up the 33 X 33 neighboring 30 m cells and the result divided by 1089 to give an approximate value of percent of each land use within 1 km of center point of each 30 m cell.  Missing values, for example along the coast and boundaries of the study region were treated as zero.  The focal statistics tool used a mask extending 5 km beyond the state boundaries for the eastern US states defining the study area.  
 
(This follows the procedure used earlier to calculate percent urban.  Earlier we chose to use cells rather than a circular radius when we were looking at very fine spatial resolutions e.g. 50 km)

ArcGIS extract values to points tool was used with the interpolate option to assign results of focal statistics calculation to grid ids (guid) associated with AOD measurements.  The results were exported to csv files, then imported and merged together in SAS 9.2.  
* 2.Build database
*** Land use from rasters
a unique grid is loaded to GIS
-we *clip the grid* so only points inside the NEMIA area are prestent
-we calcualted the elevation and percent urban form steve melly rasters using using extract values to points
@Warning:carefully check At each step with gis statistics that the there are not alot of missing , -9999 or other weird values@
*** Create keytables
We took the full grid of NE_MIA and create full tables using `spatial join`.
we linked each time the closest NDVI, PBL and MET 'id's' (created in respective scripts that created these variables from RAW) to each individual AOD guid.
we also used a hydrology layer to flag (wflag) all the grid points falling in water bodies/ocean
*** Merge the keytables with LU/emissions in SAS
using

file:/home/zeltak/org/files/Uni/Projects/code/P31/cn004_Landuse.sas

we now have a final keytable with all ID's and LU terms

*** create a near water areas variable
in order to exclude points near water bodies we used the following method:
we loaded the hydrology across NE/MIA, then we take the unique grid and spatial join e 
then we create a 0,1 Variable for , is near water (0=no 1=yes) based on if its within a 1km dist or -1 (not within search radius)
%NOTE%: some manual editing to convert some point to 'water' points was still needed (with the help of an overlay bing map)
This is added to the general LU grid

*** Create a subset of AOD relevant to stations (within X km if stations)
Step1: create a key table

-create a subset for mod1&-

1) we import the PM stations locations

2) we then select by location only the points within X distance from the monitor stations (1km).
%NOTE: depending on what we decide we define a search distance (below for the 10x10km data its 13km, it will be different for the 1x1km data)%

#+attr_html: :width 700px
[[file:~/org/attach/images/2542013w6.png]]

this selection is then exported to a dbf here:

F:\Uni\Projects\P020_Temprature_NE_MIA\3.Work\2.Gather_data\FN007_Key_tables\AOD_within1km.dbf

re-import the file using import XY

then the file AOD_within1km.dbf is joined  to the met_full_grid to add the station variable to all these AOD points to this file in the geodatabase:

AOD_within1km_met

#+attr_html: :width 700px
[[file:~/org/attach/images/2542013w7.png]]

this is exported to dbf (AOD_within1km)

*** generate near table (calculate the 100km buffer for every grid cell)

We want to get !all grids within 100km of a pm station!

first load the unique grid with lat/long

and the relevant pm station (pm_stations)

then issue this process (generate near table) :


#+DOWNLOADED: file:///home/zeltak/org/attach/images/img14062013p3.png @ 2013-11-09 10:55:09
#+attr_html: :width 500px
 [[~/org/attach/images_2013//img14062013p3_2013-11-09_10:55:09.png]]

the above generates the near Table. you can see the !IN_FID! (the objectID of input feature- PM ) and !NEAR_FID! (the objectID of near feature- GRID)

1)first issue a join to the neartable the PM (monitors) feature layer
based on !IN_FID! (neartable ) And the original !objectID! (PM)
2)Followed by another join to the neartable with the unique grid(the GRID) based on !NEAR_FID! And the original !objectID! (of the GRID):
3)then the final result will have the attributes of both original table and then near table

this is exported here:
f:\Uni\Projects\P031_miacPM\3.Work\2.Gather_data\FN015_withinkm\km100.dbf

*** calculate per day mean 100km temp per guid
using script

c:\Users\ekloog\Documents\My Dropbox\uni\~code\NE_MIA_PM\org\cn010_macro100km.sas

We calculate a per day per guid temperture reading that is the mean of all met stations within 100km from that grid cell.

the resulting files are here:

f:\Uni\Projects\p031_MIAC_PM\3.Work\3.Analysis\AN_001_mods\final_100kmet2003.sas7bdat
*** LPM 200m
**** join X,Y of lpm grids to LU/Met variables
we load the X,Y (x_alb and y_alb) file to GIS (file:/home/zeltak/smb4k/ZUNISYN/ZUraid/Uni/Projects/P031_MIAC_PM/3.Work/2.Gather_data/FN004_LU_full_dataset/GRID_lu200_XY.dbf)
We then use spatial join to join it with the all variables (LU/met/etc) IDS:

'GUID_pblid_NEMIA_distPE_wflag0_ndviid_regions_metID'

this file is exported here:
file:/home/zeltak/smb4k/ZUNISYN/ZUraid/Uni/Projects/P031_MIAC_PM/3.Work/2.Gather_data/FN007_Key_tables/LPM_GRID_IDS.csv
*** alternative MPM calculations tested
cn010_create_mpm_No_miss.sas creates full PM data sets for all years taking closest monitor for that day when missing. runs for all years 2003-2011
* 3.results
  
