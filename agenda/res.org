#+TITLE: Research 
#+TODO: TODO(t) TASK(f) EXP(e) | PAUSED(p) DONE(d) 
#+CATEGORY: work
#+TAGS:  allan(a) joel(j) meytar(t) boris(b) BGU(u) maayan(m) adar(d) omer(o) lara(l) hila(h) students(s) itai (i) alexandra (x)
#+STARTUP: overview  inlineimages eval: (org-columns)
#+OPTIONS: toc:nil 

* Active Projects
** P000_TMP_PROJECTS
** P002.MIA_PM_MODELSV3
*** code
*** actions
*** Manuscript
**** related papers
** P003.TEMP_MODELS
** P006.NAS
** P007.Zinc
** P009.Jamie_Worcester
** P010.Medicare_NE
** P011.BirthW_NE
** P012.MORTALITY_NE
** P014.BIDMC_project_Fram
** P017.Medicare_MIA
** P019.VIVA
** P020.Temprature_NE_MIA
** P021.Temprature_ITALY
** P023.Temprature_Israel
** P029.BC_model
** P031.MAIAC.France
** P031.MAIAC.ITALY
** P031.MIAC_PM
** P032.multiple_expo_jaime
** P033.MIAC_MEXICO
** P042.Medicare_DVT
** P043.BirthW_Temp_MA
** P044.NAS_MAIAC
** P045.Israel_LST
   :PROPERTIES:
   :ID:       a50ca683-36db-45ee-b5c0-9adeea1ca8d8
   :END:
*** code
[[file+emacs+dired:/home/zeltak/org/files/Uni/Projects/code/P045.Israel_LST][/home/zeltak/org/files/Uni/Projects/code/P045.Israel_LST (dired)]]
*** actions
*** Manuscript
**** how will we differentiate it from NE paper:
-completely different geographic region with med climate in south ,alpine in east and north-european in north
-focus perhaps on paris and spatial variation across the city
-seasoanlity
-Submit to a Euro journal
-compare the model to avilable models in europe.
- While we were successful in developing such a model in the Northeast, performance in Europe is unknown where land use patterns are different, and where there are sharp climate gradients such as mountainous areas, cold Atlantic shores Mediterranean climate, etc such as in France. I would also point out that the model has shown its advantages over nearby temperature monitors in health effect studies already.  I would try Atmospheric Environment.
**** related papers
** P046.Israel_MAIAC
*** TASK check in Israel for next iteration
 composition of PM in israel
 teom at 50 celsius  may over measure and introduce noise to pm25.
 look at average residual in monitors 
 put that in the paper teom is limited
 -why do we correlate 24h and not by overpass
 -better regions
 -a mean 20km mpm excluding the actual monitoring data. works very well as predictor but we have mod 2 problem. Also David dosent like it.

*** Meetings
**** ILAN YUVAL meeting [2015-09-01]
****** base for meeting
 no real need for 3 competing models
 combine all into 1 model
****** SPACE TIME DATASET
******* data available
******** monitor data
 data base by yuval
 half hourley data based on MOE monitoring network
 most pollutants in israel and meteorological variables
 Itai's student is working on met data from all stations in Israel (not only MOE) - will contact yuval
 check if he has data from-MISRAD HAHAKLAUT AND MACHON METEOROLOGY
 also met data
 ozone
 toluene/benzene
 etc
 traffic data from "decell"-traffic velocity and density (Ako to BSV including Jerusalem)
 David's student Shimi is working on a model based on the "decell" data with weekends/holidays/seasons
 POPULATION DENSITY-2012
 point emission inventory (shimi has been working with it), nox,sox,pm2.5,pm10,nvoc
 VOC from populTION-population density*factor; how much does it affect the model??
 Hourly wind direction/speed field 3km resolution
 PM and dust
 street map

 Itai 
 NDVI-1km
 surface reflectance-create land use map based on the sr data (future project)
 Roads map
 LU

 MOE
 country predictive model  - emission rate from traffic - 4 metropolins (from 2002)
 annual data based on working days and private cars

 LANDSAT
 PBL- Beit dagan and davis studetn
 elev-from aster
 analyze raw satellite radiance data and relation to pm


 ****Ideas****
 diurnal cycle of pm data
 analyze raw satellite radiance data and relation to pm
 speciciation of particles - jeremy data from 2007, get samples  data from MOE (ilan)
 Yael Etzion and David are working on number concentrations DYLOS technology
 we are creating a database - who will be in charge ? david/itai

 next meeting - october 2015
 meytar send raw aod data to ilan~

****** state strength and weakness of all models
******* aod data
 we don't expect a good liear corr between aod and pm
****** see which spatial/temporal data each group has and combine them into a joint pool for all future exposre studies
****** check spciaction from MOEP to see which componenets (traffic vs secondary ) are in each city and vs rural areas
 will be also good for goescehm model
 ask david about that
 borrow a haravrd based filter- talk to petros



** P047.BW_MAIAC
** P050.Haifa.Mon
** P051.PAD_NEMIA
** P052.noise_expo
** P057_helena_Vertprofile
** P065_Aqua_Tera_calibrations
*** use of aqua and terra as 2 separate exposures
instead of calibrating: one would be a peak level exposure and one a "background" exposure
 calibrate with hourly 
 terra > 9:30
 aqua > 14:30 
 talk to petros
we want to show that one picks up traffic well while the other picks up transported PM mainly

** P067_Yom_kipuer_lagbaomer_MLR

* Future Project Ideas
** Model.PM 
*** Ideas (NEED TO QUEUE BY PRIORITY)
**** [#B] use spatial regression (spatial error into the model)
http://www.ats.ucla.edu/stat/r/faq/spatial_regression.htm
**** [#B] comparing global spatial patterns ans errors in all modeled areas 
**** [#C] apply a SVM model in mod4 (localPM)			       :itai:
**** [#C] Joels random intercepts per cell
I have been thinking about the issue of the random intercepts for cells, specifically why they help and what they do. A random intercept for a person in a repeated measures study represents the fact that on average their level of outcome differs from the mean. I basically captures the mean residual for subject over the repeated measures. Similarly a random intercept for a cell captures the mean residual for that cell for that year. It says that some cells, on average, have mean positive or mean negative residuals. So it can help with spatial R2 but not temporal. 
Now putting in the random intercept in calculating R2 is cheating because we don't have a random intercept for cells without monitors. But suppose we did. Suppose that the spatial pattern of the random intercepts was not high frequency noise, but actually showed some pattern? Then we can take the annual mean residual for each cell in a region that has a monitor, and smooth it spatially. For example,

spat<-gam(resmean~te(lat,long))
Then 
pred<-predict(spat, newdata)
where newdata has the lat and long of every grid cell centroid.
Now we do have a value that we can add to each grid cell to improve spatial R2. And if we do5-fold  cross-validation with leave out monitors we will not overestimate our spatial R2. We do this for each year and that should help.
Another approach (which can be combined) is to think that one reason the grid cell prediction is different from the measurement is that the monitor is not located in a typical location for the grid cell. We can capture that by adding some land use terms within 100 m of the monitor.

For temporal variability, the only reason I can think for having a lower R2 than expected is that temporal change in the AOD is not capturing all of the temporal change in the monitors. Why? 
One reason is that there is always some dust coming from the Sahara when the wind is from the south, so I think a dummy for wind from 181-365 degrees may help. The AAI from OMI may also help, and Qian Di is working on that for you.
Another is wood smoke, which produces primary organic aerosols, which AOD is not great at detecting. Again OMI may help. 
Another is secondary  aerosols. Our GEOS-Chem modeling shows bands of OC outlining roads (but wider than the EC bands). So I think that NOx emissions may help capture this. 
Finally, when Qian gets a chance, I will have him run GEOS-Chem for Italy. We have the preliminary run done, but we need to calibrate it with the monitors. I know he got monitors from Kees, and Itai said there were more, but I forget if you sent them to him.

**** [#A] predict pm25 from 10					     :meytar:
weight the predicted pm2.5 as lower weights opposed to true PM10
**** [#C] Compare results between correlation to MAIAC/MODIS C06 AOD data with overpass data (i.e. mixed effect model). :alexandra:
**** [#A] Use SVM with random statement				      :allan:
tried with mediocre success so far- is there a way to include a random statement
**** [#A] Run model annually per country per region in different countries- FRANCE, johanna :meytar:
(do the regions with poor results have similar characteristics?) but present evaluation on a daily basis – show annual distribution of daily r2, rmse. Etc.
**** [#D] Check with Brent Coull the possibility of incorporating the predicted temp (from the temp model) into the PM model.
**** [#D] Run the model separately on subsets of the available collocated data based on high/low PM conc.
run logistic model to classify high or low data. high data for pm like 200+ etc
**** [#D] Study the angles during retrievals (and their link to the % dark pixles) and surface reflectance
**** to borrow information across space create a variable that weights and down weights low aod observations per day
**** [#A] LUR; space-time smoothing; nearby cells weighted for missing and previous day (if gone, use today)
**** [#A] does relationship of Aqua and Terra give us info? early pollutant build-up vs continuous across the day? :meytar:newdata:
pick satellite (Aqua vs Terra) based on which one has lower uncertainty in gridcells that join to monitors 
**** [#D]  Use aeronet - maybe as a super-monitor (weighted?) Use other satellite data?
**** Use a latent class linear mixed model (LCLMM) to generate PBL patterns as predictors (see ?lcmm::hlme); 
See also Schafer et al.
**** Proportion of the day with wind from the north (if point sources matter)?
**** Andrew Ng's strategy for assessing bias vs variance in prediction algorithms (see coursera videos) :allan:
****  Should we try to impute missing PBL (especially runs of multiple missing days) 
**** Construct directional buffers and intersect these with road density for each point;
  consider upwind traffic on each day (directional road density weighted by daily wind)

**** spatial join to best close point
 Instead of taking the closest AOD point to each monitor for each day, what if we took each of the points within some distance and ran a regression then preferentially weight our selection AOD points to pick those sites with best agreement to monitor (likely a function of local land use features). The best agreement could be not the closest point, but the one downwind the most, or with the most similar amount of roadway, etc... This could really impact calibration in Mod1.
 see also LUR_Mex_4b_2_vignette_spatialjoin.R

**** Are there better predictions at stations with their own met monitoring?
  does it matter if you have the spatial/temporal covs from your own monitor Vs. borrowing it from nearby
**** Does open streetmap give the same predictions as municipal GIS
**** For any pair of monitors, what is their correlation as a function of distance (manual semivariogram)
**** Are seasonal patterns driven by rain alone or rain + other factors
**** If there are temporal patterns (decreases) are any particular predictors major drivers of these trends (interaction by time)
**** If we compare school monitor stations with closest SIMAT monitor - how good are they?
**** Fix R code to convert latlon to UTM 14N
**** Why is our mod1 dropping UIZ and SJA in much of 2007 - it looks like there was daymean measured there before :newdata:
**** Add no2 and co; indicator for days with high co to pm ratio (top third), same with no2	 	
  using additional monitoring data (co-pollutants) as an indicator of the composition (daily or by sub-region&day)
**** Add pressure to data from noaa	 	
**** Air mex Pm 10 to pm2.5 ratio, could that change how well it fits	 	

 		
**** Calibrate TEOM against filter-based PM2.5 measure - could burn off volatiles and under-report PM2.5, maybe varying by seasons/locations	 	
**** import from HDF4 using R: maybe recompile rgdal from source? see link	 	
**** impute missing pbl	 	
 	  check out Amelia, maybe single impute time-series?
	  http://cran.r-project.org/web/packages/Amelia/vignettes/amelia.pdf
****  RH modifies particle size distribution - need to include	 	
****  scraping google or bing road traffic	 	
****  use lots of spatial terms with PLS regression a la Sampson paper 
****  seasonal patterns - are these just due to rain?	 	

**** weight sites in Mod1 by inverse of nearby missing AOD (downweight sites near clouds)
**** Joel suggests we put time interactions on almost everything
  which interaction
  file:/home/acjust/projects/airmex/code/LUR_Mex_1b_clean_local.R

**** if no points to calibrate against - maybe don't use mean slope/intercept for mod2 prediction
  what about instead clustering to find characteristics of days that predict the AOD-pm relationship
  and substituting slopes/intercepts from those instead for the many days when no calibration is occuring because mod1 is empty on that day (no aod near monitors)

**** add high res local smoothing in mod1
in mod1 file, join the monitor to average of nearby AOD
**** Workflow and fixes
**** Discover patterns of bad AOD data using spatstat to check for contiguous regions

***** create paths so S:/ and S:/EOME taken care of automatically
***** Enhance geomerge
      :PROPERTIES:
      :ID:       063b3058-0d6b-4f36-820c-adfd60cf1f8f
      :END:
don't fail on missing
don't require matrix ID to be character
better arguments inline with common gis terminology

***** joel and Bernt talk
****** Dynamic threshold of high aod (exclude high aod if monitor are low)
****** Or substitute nearby Monitor pm if aod high but Mon is low (bad ground measure).
****** Look at diurnal pattern (pm, pbl) to predict when build up occurs. Use both aqua and terra as predictors?
****** Cross validation: bootstrap prediction after leaving out two monitors with replacement, make predictions, check r2
****** Try aod divided by pbl. Or cluster groups of days (by pbl profile). Fit different models for subsets?
****** Handle data as a matrix, smooth with a weighted kernel. Strip off measures near edges.

**** add flag to exclude closest in mean calc in geomerge/nearestbyday
**** PLS regression 
**** look into Eumetsat for met data over EU/Israel		     :meytar:
http://oiswww.eumetsat.org/IPPS/html/MSG/RGB/DUST/WESTERNAFRICA/
**** add as.factor(month)*aod in model
**** look into using svm in mod4

**** geoschem model vertical profile - put into a europe wide pm dataset

**** pick satellite (Aqua vs Terra) based on which one has lower uncertainty in gridcells that join to monitors
**** look at surface refelectance and zenith
**** weight sites in Mod1 by inverse of nearby missing AOD- (downweight sites near clouds)
**** pls regression for both inclufing aqua-terra??
**** look into meris data for aod
basian latnet variable  model

**** smoothing of the residuals-lucas neas suggestion
#+BEGIN_SRC sh
vresid~ LU+MET+Interactions+ s(x,y)
#+END_SRC
**** reg calibaration instead of CV for stage 3
run the reg with some left out monitors and see if the slope is different then '0' to see if we have Bias 

**** explore Callipso sattelite 

**** supplementing AOD by space and time
     :PROPERTIES:
     :ID:       bd374907-316e-4494-bbb1-f877ef09e627
     :END:
space: perhaps taking aod from n (~ 9) adjacent cells
time: take from prev/next day if no AOD avilable today
also we can maybe weight nearby cells by missingness/distance

**** use calman filter to merge 1x1km to 3x3km
     :PROPERTIES:
     :ID:       162c23d1-7d21-4026-ac93-bbe20193c975
     :END:
we can supplment 1k data with 3k data where we preform lousy and dont do so well
**** look at interactions with wind 
random slope for each slopes for each wind direction
use wind speed to choose the best 9 grid cell aod 
reanalysis data set for wind direction
**** LPM- rule if you have a spline it should stop in distance X etc (in examp: for A1 1500km).
**** Try removing (in mod1&2) aodid gridcells that have very few passable days (<100) :newdata:
     :PROPERTIES:
     :ID:       31731f52-2f71-4a2c-80e8-31e664617df3
     :END:
since they may have ground conditions that are weird

**** NEXT calculate for each day the corr between monitor and surronding AOD point in a X defined distance and take the highest correlation:
     :PROPERTIES:
     :ID:       4a7af949-7755-4087-87d4-d711815d260c
     :END:
modis isn't fixed and we are getting the centroid of the grid
it may be that the closest AOD point does not neccesarly correlate the best in a given point/day due to:
there maybe LU/temporal variables that are not centroid specific 

**** cover less densly populated areas across USA with 3x3 data 
**** smoothing of the residuals-lucas neas suggestion
#+BEGIN_SRC sh
resid~ LU+MET+Interactions+ s(x,y)
#+END_SRC
**** Take those smoothed surfaces from stage 3 and put them into stage 1 as another predictor, and if CV R2 goes up, use them?
**** Use aeronet - maybe as a super-monitor (weighted?) Use other satellite data
     :PROPERTIES:
     :ID:       5ce7437b-68c9-4227-928e-5e222f7cb922
     :END:
**** Better error estimation
I have one other idea regarding error estimation. What I previously proposed samples spatial variability in error. We take the annual error in each monitoring location and do a LUR. But there is also temporal variability in at least the GEOS-Chem output, because the chemistry is not perfect and on some days that will matter more. For this I propose the following. On each day, for a region, e.g. New England, we compute the daily rmse. We can then regress these against temporal factors, mostly meteorological. 

**** mihyee weighted CV
#+BEGIN_SRC R
#remove.packages('lme4');
install.packages('c:/test/lme4_1.0-6.tar.gz', repos=NULL,
type='source')
#http://cran.r-project.org/src/contrib/Archive/lme4/
#If error, install R developer tool (Rtools31.exe default installation
at http://cran.r-project.org/bin/windows/Rtools/)
#After lme4_1.1-5, produces error like random coeff >= obs.
:options(lmerControl=list(check.nobs.vs.rankZ = "ignore"))
#https://github.com/lme4/lme4/issues/175
library(data.table); library(plyr); library(lme4); library(mgcv)
#Making a grand report table
#colnames(mod1table) <- c('Year', 'Group', 'OA_R2', 'CV_R2', 'CV_int',
'CV_int_se', 'CV_slope', 'CV_slope_se', 'RMSPE', 'spatial',
'temporal', 'RMSPE_spatial', 'LPM_CV_R2', 'LPM_CV_int',
'LPM_CV_int_se', 'LPM_CV_slope', 'LPM_CV_slope_se', 'LPM_RMSPE',
'LPM_spatial', 'LPM_temporal', 'LPM_RMSPE_spatial')
mod1table <- matrix(nrow=27, ncol=22); mod1table <- data.frame(mod1table)
colnames(mod1table) <- c('Year', 'Group', 'OA_R2', 'CV_R2', 'CV_int',
'CV_int_se', 'CV_slope', 'CV_slope_se', 'RMSPE', 'spatial',
'temporal', 'RMSPE_spatial', 'LPM_CV_R2', 'LPM_CV_int',
'LPM_CV_int_se', 'LPM_CV_slope', 'LPM_CV_slope_se', 'LPM_RMSPE',
'LPM_spatial', 'LPM_temporal', 'LPM_RMSPE_spatial', 'LPM_CV_2')
mod1table$Year <- rep(2003:2011, each=3); mod1table$Group <- rep(1:3, 9)
lu <- read.csv('C:/Data/Thesis/Topic 2/Data/Local
PM/pm_stations_lpmvariables_2_7_14.csv')
lu$dist_pemis[is.na(lu$dist_pemis)] <- 15; lu$dist_A1[is.na(lu$dist_A1)] <- 50
lu$elev_m <- NULL
m1.formula1 <- as.formula(PM25_2 ~ aod + TEMP.x + DEWP.x + SLP.x +
WDSP.x + VISIB.x + ah_gm3.x + NDVI + elev_m + pbl
                          + pcturb_1km + Emsn_Pt + PM10_Pt + NOX + (1
+ aod|Date/Region2))
m1.formula2 <- as.formula(PM25_2 ~ aod + TEMP.x + DEWP.x + SLP.x +
WDSP.x + VISIB.x + ah_gm3.x + NDVI + elev_m + pbl
                          + pcturb_1km + Emsn_Pt + (1 + aod|Date/Region2))
m1.formula3 <- as.formula(PM25_2 ~ aod + TEMP.x + DEWP.x + SLP.x +
WDSP.x + VISIB.x + ah_gm3.x + (1 + aod|Date/Region2))
m10.formula1 <- as.formula(PM25.y ~ AOD + TEMP.y + DEWP.y + SLP.y +
WDSP.y + VISIB.y + ah_gm3.x + Ave_Elev
                          + p_open + Ems_Pts + Ems_Cnty + A1_dist_km +
Sum_DISTAN + (1 + AOD|Date))
m10.formula2 <- as.formula(PM25.y ~ AOD + TEMP.y + DEWP.y + SLP.y +
WDSP.y + VISIB.y + ah_gm3.y + Ave_Elev
                          + p_open + Ems_Pts + (1 + AOD|Date/Region))
m10.formula3 <- as.formula(PM25.y ~ AOD + TEMP.y + DEWP.y + SLP.y +
WDSP.y + VISIB.y + ah_gm3.y + (1 + AOD|Date/Region))
ctrl <- lmerControl(optCtrl=list(maxfun=50000))
cv.records.year <- list()
options(warn=1) #Produce warnings right away where it occurs (if 2, stops)
for (i in 2003:2011)  {

  for (j in 1:3)  {

    print(paste(i, j))

    m1 <- read.csv(paste('C:/Data/Thesis/Topic 2/Results/Stage
1/Pred/Pred1 CSV/Pred1_', i, '_', j, '.csv', sep=''),
colClasses=c('SiteCode'='character')) #To keep leading zeros in
sitecode
    m10 <- read.csv(paste('C:/Data/Thesis/Topic 2/Deep Blue 10 Km/Data
in CSV/Stage1_', i, '_', j, '.csv', sep=""),
colClasses=c('SiteCode'='character')) #To keep leading zeros in
sitecode

    ####
    #M1<-PART OF SOCKET?
    #M1<-ONLY THE COMMON?
    ####

    combi <- merge(m1, m10, by=c('Date', 'SiteCode'))
    #load CV data for each aod resolution
    CV10.1 <- read.csv('C:/Data/Thesis/Topic 2/Results/Stage 1/Stage1_CV10.csv')
    CV10.10 <- read.csv('C:/Data/Thesis/Topic 2/Deep Blue 10
Km/Stage1_CV10.csv')
    #extract the RSMPE
    RMSPE.spatial.1 <- CV10.1[CV10.1$Year==i & CV10.1$Group==j, 'RMSPE_spatial']
    RMSPE.spatial.10 <- CV10.10[CV10.10$Year==i & CV10.10$Group==j,
'RMSPE_spatial']
    #create weights based on RMSPE
    w1 <- 1/(RMSPE.spatial.1)^2
    w2 <- 1/(RMSPE.spatial.10)^2
    #the j is for every region
    if (j==1) {m1.formula <- m1.formula1; m10.formula <- m10.formula1}
    if (j==2) {m1.formula <- m1.formula2; m10.formula <- m10.formula2}
    if (j==3) {m1.formula <- m1.formula3; m10.formula <- m10.formula3}

    out.m1 <- lmer(m1.formula, data=combi)
    combi$prednew <- predict(out.m1)
    mod1d_reg <- lm(combi$PM25_2 ~ combi$prednew)
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'OA_R2'] <- summary(mod1d_reg)$r.squared",
sep="")))

    #Site sHUFFLING- CV  per Site

    index <- unique(combi[, 'SiteCode']) #List monitoring sites
    suffled.sites <- sample(index) #Shuffle them
    quotient <- trunc(length(suffled.sites)/10) #Divide them by 10
    remainder10 <- ((length(suffled.sites)/10)%%1)*10
    series <- rep(quotient, 10)# take 10% of sites
    series[0:remainder10] <- series[0:remainder10]+1

    for (k in 1:10) { #set k-th CV
      if (k==1) {start <- 1; end <- series[k]} else {start <- end+1;
end <- start+series[k]-1}
      site.ith <- suffled.sites[start:end]
      combi$CVSetID[combi$SiteCode%in%site.ith] <- k
    }
    #Site sHUFFLING

    cv.results <- list()
    for (m in 1:10)  {

      trainset <- combi[!combi$CVSetID==m, ]
      testset <- combi[combi$CVSetID==m, ]

      out_90.1 <- lmer(m1.formula, data=trainset, control=ctrl)
      testset$prednew10.1 <- predict(object=out_90.1, newdata=testset,
allow.new.levels=TRUE, REform=NULL)

      out_90.10 <- lmer(m10.formula, data=trainset, control=ctrl)
      testset$prednew10.2 <- predict(object=out_90.10,
newdata=testset, allow.new.levels=TRUE, REform=NULL)

      #add the weights to the CV results
      testset$pmnew <- (w1*testset$prednew10.1 +
w2*testset$prednew10.2)/(w1 + w2)

      cv.results[[m]] <- testset
    }

    mod1d_all <- do.call(rbind, cv.results)
    mod1d_reg <- lm(mod1d_all$PM25_2 ~ mod1d_all$pmnew)

    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'CV_R2'] <- summary(mod1d_reg)$r.squared",
sep="")))
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'CV_int'] <- summary(mod1d_reg)$coef[1,1]",
sep="")))
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'CV_int_se'] <-
summary(mod1d_reg)$coef[1,2]", sep="")))
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'CV_slope'] <-
summary(mod1d_reg)$coef[2,1]", sep="")))
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'CV_slope_se'] <-
summary(mod1d_reg)$coef[2,2]", sep="")))

    #rmspe
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'RMSPE'] <-
sqrt(mean(mod1d_reg$residual^2))", sep="")))

    #spatial
    aggf<- ddply(mod1d_all, c("SiteCode"), function(df)
return(c(barpm=mean(df$PM25_2),barpred=mean(df$pmnew))))
    mod_spatial <- lm(barpm ~ barpred, data=aggf)
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'spatial'] <-
summary(mod_spatial)$r.squared", sep="")))
    aggfdt <- data.table(aggf)

    #temporal
    dat <- merge(mod1d_all, aggf, by='SiteCode', all.x=T)
    dat$delpm <-dat$PM25_2 - dat$barpm
    dat$delpred <- dat$pmnew - dat$barpred
    mod_temporal <- lm(delpm ~ delpred, data=dat)
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'temporal'] <-
summary(mod_temporal)$r.squared", sep="")))

    #rmspe_spatial (RMSPE of spatial predictions)
    dat$spatresid <- dat$barpm - dat$barpred
    eval(parse(text=paste("mod1table[mod1table$Year==", i, " &
mod1table$Group==", j, ", 'RMSPE_spatial'] <-
sqrt(mean(dat$spatresid^2))", sep="")))

    write.csv(mod1table, 'C:/Data/Thesis/Topic 2/Deep Blue 10
Km/Stage1_CV10_pmnew2.csv', row.names=F)

    #Just round to 2 decimal places
    #eval(parse(text=paste('mod1table$', i, '_', j, ' <-
round(mod1table$', i, '_', j, ', 2)', sep='')))

  }
}
#+END_SRC

**** using WRF data for met.pbl etc data (see AE I reviewed)- also look at sattelite derived column no2-from same paper 
q
**** combine aqua and terra
I have an idea for combining the satellites but we need to get NE done quickly and I thought we should save it for your Midwest paper. You should expect half or more of the observations to be missing. What is your missing percentage?
Regarding the two satellites you need to remember some stuff from Petros' air pollution course. In the morning the mixing height is low. Local pollution is trapped near the ground, an is a large fraction of particles. It is mostly from traffic or from oil heat in the winter, and so a lot of the particles are black, and a lot are fresh, and hence small. I n the afternoon the mixing height is high, transported particles mix down, and the color and size distribution change. Therefore, the calibration changes. So we need to do the stage 1 calibration separately for each satellite, and then combine, since one is in the morning and one in the afternoon. 


I asked Mihye to run separate stage one models for aqua and terra, predict the PM2.5, average the predicted and they do the CV R2, and it was higher than either. While this may not matter for the Northeast, for the Southeast we need all the gain we can get, and I expect it would help for Italy, and possibly France as well. I think it is important to do the averaging after converting to PM2.5, because they measure AOD at different times. The aqua measurements are in the afternoon, and will be less impacted by the morning peak in local pollution, and the model will depend more on local land use surrogates to capture that contribution. In contrast, much of the transported pollution has mixed down by then, and the AOD will capture that better. For terra, it is the reverse. So I expect different coefficients both for AOD and for the other terms. Once we have the best PM2.5 predictions from each, averaging should eliminate some noise in the prediction. She is doing this now for the Southeast. 

**** Aerosol index
Getting back to Aerosol Index, which is computed in the UV band not visible light, it seems to be sensitive to two types of particles: desert dust, and organic particles from biomass burning. It seems to be available on OMI and some European Satellites, and interestingly for Israel, seems to go back much further. The resolution is coarse, 25km, but it certainly will give a continuous measure of how much dust is around, and for dust from Sahara or Arabia, 25km may not be too bad a resolution. So it could help correct models using MAIAC data on "non dust storm" days when there is still some dust around. It should also help for Italy and the south of France which get hit by Saharan dust. It might improve predictions in winter where wood is burned for heat in Italy and France.


http://disc.sci.gsfc.nasa.gov/data-holdings/PIP/aerosol_index.shtml
http://www.temis.nl/airpollution/absaai/

**** data fusion in North America
combining the 3k and 1k data which have different algorithms and hence different errors
**** use calman filter to merge 1x1km to 3x3km, 10k
      :PROPERTIES:
      :ID:       51e638d4-a837-4689-b3cd-56d46777b576
      :END:
****** we can supplment 1k data with 3k data where we preform lousy and dont do so well
****** different resolution for different areas in the USA based on pop density/avilable health data
**** Brent ideas 
latent variable model 
trying to estimate latent value
smooth surface of 10x10 
autocorrelation over time to interpolate missing data 
brents idea:
we need to fill missingness by interpolate to any given grid and that interpolation where we have monitors will be a predictor
R package by lauren hunn
-geoschem combine with aod qian 
**** sattelite humidity
lowest level
*** Joels ideas
**** Idea for modeling PM2.5
Let’s think about variations in air pollution concentrations. Some are spatial, some temporal, and some are spatio-temporal. Spatial variations are driven by variations in emissions, in topography, and in prevailing weather patterns. Land use attempts to capture these. Most land use terms capture emissions. Topography is an area that could be improved, as can prevailing weather. Can we classify places as in a valley? A plain? Downwind of prevailing weather patterns or upwind?  Near the sea or lakes? These are variables that may need some attention.
Temporal variation can be conceptualized by thinking about a simple box model of the air above a location. The mixing height is the lid on the box. Wind speed moves emissions out of the box, but brings pollution from upwind. Hence it’s influence depends on the back trajectory of the air. That is, where the air over a city now was two days ago is an important predictor of its level. Importantly, it seems to me that what drives temporal variations is spatially homogeneous on a larger scale than what drives local spatial variation. That is why time series analyses work for large cities. The pollution is different, but goes up and down together. We need to capture this to improve our models.
Another key issue I see is that the effect of PBL and wind speed depends on the local emissions. In a location with lower emissions, they will cause smaller fluctuations. That is, we expect their influence to be proportional, not additive. We have tried to accommodate that with interactions with land use terms. But really, the interaction should be will all emissions from the location, not just the ones we capture with those land use terms. And if there are seasonal differences in back trajectories, then wind speed may have seasonally varying effects.
Finally, 1km is small, and concentrations that were upwind a few hours ago will be in this cell now. So it seems clear that concentrations at neighboring cells matter. The question is how to capture this.  
So I think we should try the following. First, fit a model for annual average PM2.5. Use all the land use variables, the AOD and the UV AAI from OMI. Try to add in some topographical classification variables. And add the mean AOD in an 11 x 11 km cell that has the grid cell being modeled in its center as another predictor variable.
Then, in each grid cell, instead of taking daily differences, take daily ratios to the annual average. Model these ratios as a function of PBL and wind speed, which are now proportionately changing concentrations of local emissions, not additively, as well as seasonal terms, weather, etc. Since we think relative (not absolute) temporal variation is spatially homogeneous, we can add in the mean daily ratio of  monitors within a 60 km buffer of the grid cell. The reanalysis data has estimated wind fields as well. So we can divide the 11x11 neighboring cells into 4 quadrants, look at the prevailing wind from the reanalysis data to pick a quadrant, and add in the ratio of the daily value of the 5x5 quadrant to its annual mean as another predictor. Finally, the daily surface reflectance value from the grid cell helped a bit in Qian’s models, so we should add that and NDVI. 

 Meanwhile, in diagnosing Qian's model for the entire US we note that in areas with heterogeneous elevation, the model does worse. This may be because if the land is not flat the AOD computations are more noisy. Remember what Alexei said about the shadows effecting the measurement when it was not directly overhead. I believe the ARCGIS has some ability to produce estimates of this, and they might be useful information to include. Have we heard from Alexei on the angle of view variable?
**** massimo response 
Dear Joel,

thank you very much for sharing with us your thoughts, and sorry if I am replying so late.

I try to summarize below what I have understood of your message, and conclude with some practical questions:


1. You are suggesting a very different approach, where we move from a full spatio-temporal model to two separate models, one for annual averages (chronic exposure) and another for daily ratios (acute exposures). I understand well your point, what I have not very clear is whether such approach would still allow to predict daily averages for each 1x1 location so to have epi models which evaluates short-term and long-term effects at the same time.
In aother words, are we allowed to use the ratios predictions in the second model to obtain daily PM predictions useful for short-term evaluations?

2. Let's go model by model. Annual average: I think that our predictors should allow us to characterize topography quite well. The Digital Elevation Model seems very accurate to estimate elevation of each location, distances from sea or lakes have been computed. What we are missing, but can be obtained from the Elevation Model, is a measure of the difference between elevation of the cell and elevation of a wider surrounding area, so to characterize whether we are in a valley or flat area VS a situation with changing terrain. However, we have ISA (Impervious Surface) which should tell us something about this. We have also CORINE land cover variables, but I guess they are less accurate. Finally, I don't have data on the prevailing winds as a spatial predictor, so if you have something of that kind I would be glad to add it.
Concerning the spatial model, I understand that the model is fitted on the cells with PM monitors (~400), and then I get predictions of the expected annual average PM all over the Italian domain (~300,000). Is that right? Basically, this is very similar to conventional LUR models, only with annual estimates of AOD and UVAI from satellite. Right?

3. Daily ratios: you say "in each grid cell, instead of taking daily differences, take daily ratios to the annual average". Again, I understand this model is fitted to the cells/days with PM monitors (~400*365). I model the ratio of daily PM
over annual mean PM against all temporal predictors, and I finally get an estimate, for each day and 1x1 cell (~300,000*365) of such daily ratio. Right? I am not sure I completely understood the issue of wind quadrants, and I suppose the re-analysis you mention has been done in your group and is an additional variable we could add the to dataset, right?

My final question, which goes back to the original one, is: are we allowed to use these predictions of daily ratios, from Model 2, to estimate daily concentrations? Basically, to apply the simple formula:

E.PM10(ij) = E.PM10ratio(ij)*E.PM10annual(j)

where:

- E.PM10(ij) is what we seek, e.g. the estimate (E) of PM10 on grid cell j on day i, j=1...300,000, i=1...365

- E.PM10ratio(ij) is the result of the second model, namely the estimated ratio between daily PM10 on day i and grid cell j, and its annual mean in grid cell j

- E.PM10annual(j) is the result of the first model, namely the estimated annual PM10 concentration on grid cell j.


Now let's go to the operative issues: If you agree, Joel, I would see your new approach not as a replacement of the original one but as alternative. In other words, I would proceed with the original approach (I have been working a lot on it and would like to show you some results), and would apply the new one on a test year, to see how they differ.

Let me know what you think about this.
** Model.Ta 
*** stage 3 regression by grid cell
You do not need to run a model with a random effect for each grid cell. Instead, you can run a separate regression for each gridcell, regressing the non-missing predicted Ta against the mean of monitored Ta within 100km. This gives you 1 million regressions to do, but you can divide the gridcells into 100 groups and run 100 jobs on the cluster and it will run in an hour. We do this when we regress the 5000,000 methylation sites against predictors in the NAS.  Also, we need some of the land use terms.
*** tmin tmax use 4 measuremtns per day and use aqua and terra talk to
*** calibrate aqua and terra seperatly and then average them after the callibration stage (pre mod2)
** Future exposure models 
   :PROPERTIES:
   :ID:       03c79a3e-10b4-4295-b91f-d0c4f38e9497
   :END:
     :PROPERTIES:
     :ID:       6d4ad710-4e3e-42ee-a6d0-510562544802
     :END:
N02-eurpoe issue more disel
O3-Is worth having models
light at night
** urabn plan-climate change paper 
1. מערכות חברתיות-כלכליות הן כאוטיות במהותן ומאד דינמיות, בלתי ניתנות לתחזית ולתכנון. התיאורייה התכנונית ספגה ביקורת רבה במשך שנים - על כך שהיא מבוססת על תחזיות ארוכות טווח ועל תיאוריות "קבועות".
2. על רקע זה, התכנון הולך וזונח את ההתבוננות בתחזיות ארוכות טווח ואת ההתבססות על תוכניות ארוכות טווח. השינוי רלוונטי הן לתיאורייה התכנונית והן לפרקטיקה.
3. בשונה מהמערכות החברתיות-כלכליות, מערכות סביבתיות הן אמנם כאוטיות אבל הרבה פחות דינמיות. מאחר והן גדולות מאד, תהליכי השינוי שלהן הם איטיים. המשמעות היא שניתן ברמה גבוהה של וודאות לייצר תחזיות טובות ואפילו טובות מאד לכמה עשרות שנים קדימה.
4. הבעייה: התיאורייה התכנונית פסלה את ההתבססות על תוכניות ארוכות טווח, והפרקטיקה התכנונית אינה בנוייה להתחשבות בתחזיות ארוכות טווח. כך קורה, שבישראל אנחנו הולכים לקראת קטסטרופה אקלימית צפויה וודאית - ואין כלים שיעזרו לתכנון להימנע מכך. הכלים הקיימים מתבוננים במציאות הנוכחית, ולא מסוגלים להתמודד עם מה שיהיה (בוודאות רבה מאד) בעוד 50 שנה.
     
** Black body radiation
black particles are going to observer and scatter roughly the same ammount vs other particles wont. it might be possible in NEW-England at least to use that information on how to use the diff on wave lenghts in aod for BC model.
    :PROPERTIES:
    :ID:       2a65cb66-1218-4ad7-8467-d80dc3d84cf1
    :END:
arange a skype call with alexie
** Mortality and Ta in Israel
** NAS temperature analyis
*** DONE create exposure datasets
*** test various previous temp-nas studies
    :PROPERTIES:
    :ID:       f208d9f9-92c5-4a17-9fb0-bea044ab1681
    :END:
Re-run previous studies with NAS and TEMP using a central monitor and
see wheather this improves things. if not its also ok to write a paper
about this
-try using the same models used in the paper with our NAS data
** LAN project with Joel
*** LAN in NEW-England
**** Email DMSP regarding data purchuse
     :PROPERTIES:
     :ID:       199c0727-d677-4471-8d2e-239ac3644405
     :END:
*** Send email to chris/DMSP to check calibrated LAN avilabilty
    :PROPERTIES:
    :ID:       df50eb25-0f99-4fd3-917b-628350a27935
    :END:
*** joels ideas
**** look at areas with low LAN measurements  and effect to lower LAN
**** look at a way to break the LAN-popden correlation
maybe use living near highways (A1 vs parkways vs low density roads)
*** light at night in Georgia- W/Joel
Joel has mortality data
 
** LAN ideas Boris
*** create a model to predict LAN wave lenght models
*** use LAN maps to describe Land Use
** Temperature model results and Liu CMAQ results
 -look at mortality cases and temperature (short term, acute temprature days), and compare results with our model and CMAQ
** go back to the ICAM/VCAM reanalysis
-stacey re-analysis with 1kmx1km data : We should say that we see an effect for both the year lag and medium term but the longer lag is more important
-calculate the residuals between our model and the BC model
create moving averages of the 4,8,12 weeks and try that in the model> will capture only non traffic exposures
when we get the 1x1km data ready go back to the icam/vcam reanalysis by marie-able and the stacey BC paper and see if that changes things
** explore Mapi Maagal project 
Zipcode proxy
** Understanding the local PM vertical profile			     :meytar:
Data from:
(1) Calipso
(2) MPL - Nes Ziona (Karnieli/Smadar - David Please check with her)
(3) Is there any vertical data from Aeronet?
** PM composition detection using Satellite observations (Israel, Arizona, Spain, Italy, Cyprus and more) :meytar:
- Using PM composition ground measurements as an evaluation.
- Broad cooperation, Large Grant needed 
** Understanding the limitations of satellite remote sensing over coastal areas :meytar:

Compare PM estimation ability by AOD over land with data over coastal areas, examine the coastal flag in MODIS/MAIAC algorithms.

Humidity models and profile from satellite observations	     :meytar:
As the difference in RH between the ground and satellite measurements may derive the discrepancies between these measurements, it's worth analyzing the contribution of the satellite-borne RH profile and maybe find a RH correction factor to use in PM prediction models.

** Dust classification project with India/Italy			     :meytar:
**** ask maayan
     :PROPERTIES:
     :ID:       c14fab7f-6578-46ba-b9bc-48156f8c4fa9
     :END:
how many hours of dust exposure is relevant to see an effect, did you guys look at daily means, or hourly data by any chance? know of relevant studies on that, weight exposure by ammount of hours of dust days.
**** application of prev methodology in italy india-define dust events based on PM10 and modeling
- output will be definition of dust event- hourly (0,1)
- 2 completely different geo-climate regions
-test weather israel classification methodology works in other regions
-if not model adjustments locally
-check this definition vs italy model massimo has
**** incorporation AOD 3km data for italy and India with OMI data to better 
take AOD and OMI (observing index) and take the israeli classification and try to classify days to dust and non dust.
use the Satellite data to classify dust days and once you have this classification compare tro israeli model. if there is agreement generate for india where there isn't pm10 data and use that to go back and classify. 
* Finished Projects
** P001_NE_PM_MODELS
*** code
*** actions
*** Manuscript
**** related papers

** DONE DVT admissions and PM
  :PROPERTIES:
  :ID:       2668bdf2-f4de-40cd-b57f-101a88076ba7
  :END:
*** info
The variable thromb is based on the first main diagnosis of admission, while thromb2 is based on primary and secondary admissions.
The ICD are below
thromb=0;
if (icd11 in (415, 451, 453)) then thromb=1;
*** secondary stage
**** Ask antonella about medical history, prev admisons, causes
-look into weather had cancer yes/no
-hospitalized last 90 days
**** add interactions
:PROPERTIES:
     :ID:       bd8bcdf7-4bbc-44f4-a7f2-eb65bdd2d333
     :END:
- for c-xover try individual level and zip level SES, sex, urban-rural
- interact with ndvi/percet of open space in both short and long term
  (CXover and Ts)
-look at interacting with season (winter vs summer)
**** Survival analysis
     :PROPERTIES:
     :ID:       8e80e09e-3dba-4bb1-a09e-50c09b8b28f5
     :END:
Try running a survival anlysis or maybe a posion survival analyis (SA) (look at johana 6 city paper)
if running a posion SA we can extract the random slopes fro every zipcode and with smoothing create a spatial map showing risk areas
*** Smooth the random slopes to create risk maps[
** DONE P022.Temprature_France
*** code
[[file+emacs+dired:/home/zeltak/org/files/Uni/Projects/code/P022.Temprature_France][/home/zeltak/org/files/Uni/Projects/code/P022.Temprature_France (dired)]]
*** actions
*** Manuscript
**** related papers
* scheduled mail/calls/meetings
** Alexei Mount Sinai[2015-09-18 Fri] 
   :PROPERTIES:
   :ID:       2886dd90-c077-4621-92c8-f810d30cc5d3
   :END:
*** actual talk
**** India
india should start processing soon (talk to alexei about it)
Joel has collaborations in the south of India
we need to maybe organize a skype call between all groups
**** organize a big skype call
talk to Varanasi professor. 
**** send israel pm data					     :meytar:
send alexei pm25/10 data over israel (mainly tel aviv and haifa)
**** explore different slopes based on MAIAC proccesing path or type of algorithm
ask alexei in an email for details on that and when can we get it in the data
**** why is pm 10 better then pm25
perhaps road dust that keeps circulating in the air
**** talk to alexei about dynamic models
different models in summer vs winter.
maybe coast vs other models since humidity is a big isssue in maiaic. the model assumes that particle size growth grows with high humidity
**** TASK stratify corr models by humidity
**** look at using maiac ndvi 
use already available data
Rb2-Rb1/Rb1+Rb2
**** ratio between column water vapor and AOD- ask meytar to talk to bob chatfield about this:
this seems to work better for aqua?
**** particle counter measurement on the ground- more aeronet stations to calibrate can improve the model greatly.
**** look at the SD and range of pm and aod in each station
**** Joel imputes AOD from geoschem when maiac is missing?
**** characterize lu,vegetation,surface brightness etc in each bad a good aod-pm corr pixels
**** long term-look into VIIRS and goess-R for future aod and maiac aod solutions
**** night AOD
*** issues 
**** cloud cover issue in Mexico; grid cells being masked because of bright surfaces (false clouds) and dropping of clear days- (long time series with no scene coverage)
**** Israel data subsets with no raw correlation - Itai will send examples to Alexei (related: not certain why we have big differences in R2 from year to year in Israel and Mexico)
**** dust days not caught by MAIAC (in Israel); Itai and Meytar sending a few examples
**** both areas-Focus on improving a single year to speed iteration - we nominate 2004 - hopefully this lets us communicate back and forth.
**** PM10 in Israel performs much better than PM2.5
the differences are huge- CV R2 pm10=0.82 and pm25 ~0.7
over fitting isn't the issue since also in a parsimonious model we still get this drop
***** histogram on dust days of AOD

 #+DOWNLOADED: /tmp/screenshot.png @ 2015-02-11 09:15:22
 #+attr_html: :width 450tx
   [[/home/zeltak/org/attach/images_2015/screenshot_2015-02-11_09:15:22.png]]   
 #+DOWNLOADED: /tmp/screenshot.png @ 2015-02-11 09:16:30
 #+attr_html: :width 450px
  [[/home/zeltak/org/attach/images_2015/screenshot_2015-02-11_09:16:30.png]]

***** raw lm corr aod and pm25/10 on dust vs non dust days 
0.16 non dust days
0.17 dust days

look at time series analysis
***** raw correlation with regions
 reg5      R2   nsamps
 1    1 0.39621    484  beer sheva
 2    2 0.19817   7096  ashdod
 3    3 0.30556    124  jerusalem
 4    4 0.12481   3885   Tel aviv 
 5    5 0.16421   4627  North 

 in general raw correlations aren't great- 0.001-0.3 when breaking down to season/year etc
 there are specifc station in speific seasons that have a base correlation of 0

 we saw that UN and adjancecny mask werent helping that much

 -alexei raw correlations in california from slides
 we saw in table and el segundo bad correlations in the range that we saw, whats the pysical explenation for this
 -lets take one year 2004  and focus on this. we will send you pm data. lets try to debug this
 issues we hypothesis: humidity and salt along the near shore area.
** Itzik
itzik has where each dessert strom arrived from- could be useful for health outcome studies
what we have here is teom- env monitor- cost 
** david skype call [2015-10-13 Tue]
Alexei meeting [[id:2886dd90-c077-4621-92c8-f810d30cc5d3][Alexei Mount Sinai{2015-09-18 Fri}]]
I have a post doc for 6 months..what to do with her:
ask about southern campign
aeronet campign
vertical profile
*** TASK explore with alexei sun photometer
*** TODO write brent about mixed model meeting
*** talk to allan about the intercept vs day
*** TODO dylos monitor-check google 
total count not mass
have local tel aviv , jeruslaem etc devices $750

*** ask about the MOST  ad BGU RA to see 
** Alexandra
*** shai kaplan
**** works on WRF model to first look at geo-climate changes in israel 2010 compared to 2050
**** TASK another paper looking at these changes and what they mean for urban planning and urban development-perhaps cobine forces there?
**** BSV and different climate scenarios- the WRF 1km data level is to coarse for that
*** ADAR
**** EHF aim 1- develop spatio temporal Air temperture modles for israel

COMPARE  4 models :
alexandra model  (lansat)
adar model
kriging
monitor statiobns
*** MAIAC
**** base correlation in israel pretty bad
AOD-PM raw regression sucks 0.1-0.15 R2
what cleaning methods do you do
do you see temporal diffranecs and or spatial differences in israel
**** model for epi study Haifa-BSV area
**** low yearly aod values and compared to DB which is higher in south of israel
     :PROPERTIES:
     :ID:       2e8f3c0f-f1a7-4cd3-a9f8-e7a716aec127
     :END:
we should look at wind speed from reanalysis data/station to see if these areas have low or high ws values

**** look at azimiths
**** meeting with Alexei- Joel invited him 
do you have any questions to raise
**** composition of PM in israel
** Victor [2015-10-15 Thu] 
   :PROPERTIES:
   :ID:       98b55cc3-67bf-4748-8375-515cdd5565ae
   :END:
[[id:c14fab7f-6578-46ba-b9bc-48156f8c4fa9][*** ask Victor]]
*** grant with joel
*** meytars work
*** PAD paper- discussion
*** talk to joel about specific grant 
bio staticiall grant with dealing with denominator availability and relevant statistical methods for that 
multi exposure?
non anthrpogentic dust?
** Johanna [2015-11-10 Tue] 
model 
2004 vs 2011 in terms of sd and variation in each step
** Kees [2015-11-18 Wed] 
1- the main idea of the paper will be to compare OSM data with
governmental or commercial data for a simple epi study - maybe health
impact assessment. 

2- compare 3 developed countries: Israel, Switzerland and USA
(Massachusetts). 

3- ask Keis for Switzerland data.

4- use the same grids that were used in Switzerland for Israel and
USA. (each grid contained length of roads and other data..) 

3- an idea for future study - compare an epi paper that used
commercial GIS data, and replace it with OSM data - see if there is a
difference. 
** indian meeting [2015-10-22 Thu]
** joel talk [2015-11-19 Thu]
*** new qian mode 
-will this replace aod based models? it seems like it preforms almost as well in NE
-should we have a study comparing performance in a health outcome study?
- the HEI representative in ISEE told me francesca won the grant, will this be used for the grant?
*** recommendation letter
need a really impressive "killer" over the top recommendation letter from full professor which never published with me. who do you recommend?
doug dockert?
Francesco forresteri? (is he accameimcal affiliated, that is a full professor somewhere?)
*** Europe project
kees coming In Janurary, we want to explore the pm25/10

*** send joel indian guy details
*** TASK new PM israel model 
Run svm with multiple data (10,3,1,geoschem) and add temporal interactions such as month to have a "random" effects where parameters vary by period
Qians nurel network- trains it with LU and geoschem in aod points to predict AOD and then uses another nueral network with multiple data such as maiac, omi, geoschem etc to predict daily
*** TODO check kernel machine of xihong
http://www.hsph.harvard.edu/xlin/software.html

we can use the additonal random statement to run a daily calibration
** brent[2015-12-03 Thu] 
*** [#D] Check with Brent Coull the possibility of incorporating the predicted temp (from the temp model) into the PM model.
** David and meytar[2015-11-2qx4 Tue]
*** Continue with pan israeli cooperation's
when will be the next meeting?
what to discuss?
participants?
*** Meytar time frame-when would she leave
which project invovled?
how to finish the projects by summer 
*** MOST project..if/when we get the money
alexandra stein- a good candidate to take over
*** master project to look at particles on the south
find a master student 
buy devices-dylos
find a master student to work on the project-hopefully soon or by pessach
*** vertical profile project -helena
look at calipso and or mpl and lidar
look perhaps at italy and france/
place of aerosols in the vertical profile.
*** indian varanasi project with dust classification
use yuval model with local prioritization since the dust properties are very different (suspended dust from roads, different dust storms, biomass fuel)
*** send David land use terms we can use. 
** Jaime [2015-12-15 Tue]
** Brent [2015-12-18 Fri]
Points for Discussion:

(1) Why is there such a difference between the use of date (actual date; date format) and doy (factor of dd/mm) when using a linear model and then a completly different pattern when using a mixed model? (When using a numeric index in model 2.1 instead of date it gives an r^2 of 0.358 and rmspe of 5.67. How does the use of date format affect the model?) 

(2) Is a mixed model approach the best method to use for predicting PM2.5? we see that the contribution of AOD is minor on top of the main date predictor (not so much the case when using doy where aod adds ~ 10%). what are your thoughts on this? is there 
another approach that will allow us to evaluate the contribution of AOD in the model driven by date.

(3) Since the date clearly has the strongest effect, any other variables we add are marginly contributing to the model. are there alternative modeling approaches we should explore? we were thinking about SVM, PLS and maybe a SVM+random component?  adding spatial auto correlation?

run 4.1 model first to callibrate aod to pm scale
use predicted 4.1 and rgress vs LU terms 

4.1 take slopes and multiply by aod and add it as a term in svm , also add the random slope

aod* whats that 

spline on aod- fit a gamm on aod

fhat calibrated aod into the svm 
** Tal/michael grant meeting
*** grant: "environmental factors” in the built environment and property values
**** literature review
-What are literature-known “environmental factors” and how these factors pertain to property values
-Key studies in Israel and globally looking environment and property values, what methods have they used? spatio-temporal resolution, data sources?
**** aim draft
***** develop a holistic view on all known environmental factors pertaining to property values in Tel-Aviv:
    more specifically: What is the scope of positive or negative environmental factors and their impact on property values?
***** develop discrete indexes/scores per factor and overall index/score?
***** develop open source/create common tools to approximate environmental "exposures" and provide a viable data dissemination structure
we will use R, python, Qgis, GRASS to develop these tools
**** Geo-statistical exposure Models
***** walkability
We aim at developing a consolidated walkability index, which will be based on Z-scores of individual built environment components described below.

Based on data from the ICBS and MAPI We will create address-level measures of population density, business counts (as a proxy for accessibility),intersection counts (as a proxy for street connectivity), Traffic direction, walking obstacles, traffic lanes and parks. 

 - Business counts will be measured by the counts of all stores, facilities, and services in a network buffer around each address which will include grocery stores, restaurants, banks, hotels, hospitals and libraries.

 - Intersection counts (as a proxy for street connectivity) buffers will be calculated around each home address. We will quantify the number of intersections that are 3-way or greater within each network buffer. A greater intersection count increases the efficiency of walking to destinations. 

 - We will also include traffic lanes, traffic direction, walking obstacles as additional model parameters.

Because all measures of the built environment are correlated, we will create a standardized walkability index based on the above mentioned measures.

Z- scores will be created to standardize each individual component of the built environment. These scores will have a mean of 0 and a standard deviation of 1. We will then summarize these scores to create a walkability index that combines all components of the built environment measured in this analysis. The final walkability index will have a mean of 0  with higher values indicating higher levels of walkability. 

***** Greenness
Exposure to green, natural areas around at each address will be estimated using satellite-image based vegetation index. Chlorophyll in plants strongly absorbs visible light (0.4-0.7 µm) for use in photosynthesis, while leaves strongly reflect near-infrared light (0.7-1.1 µm). The Normalized Difference Vegetation Index (NDVI) calculates the ratio of the difference between the near-infrared region and red reflectance to the sum of these two measures, and ranges from -1.0 to 1.0, with larger values indicating higher levels of vegetative density 

For this proposed study index, we will use data from the Moderate-resolution Imaging Spectroradiometer (MODIS) from NASA’s Terra satellite. MODIS provides images every 16 days at a 250m resolution (Carroll et al. 2004). We will use GIS based  software to link the  NDVI data to each address as a measure of greenness directly accessible outside the address

***** Noise exposure 
We will map and predict spatially resolved noise pollution at high resolutions per year 
We will develop novel noise exposure modeling, based on land use regression modeling, allowing robust and validated long term noise estimation at a high spatial resolution. 
We will check for seasonal and diurnal differences (looking at different aspects such as rush hours vs non rush hours)

***** temperature modeling: showing heat island effects, there could be several degrees deiffances...could affect pricing?
***** light at night
 DMSP satellite allows 600m resolution. new satellites  (such as NASA-VIIRS) can produce higher res data (~400m)
***** web data social/location based services
  mapping access to health, healthy food, business counts
***** crime-data availability
** skype joel [2016-01-27 Wed]
*** ask about noise estiation mode use of svm
cant get and coef and or summary, how does one evaluate and report the model
joel: include all interactions and all squres and cubes..takes a hugh dimensonal vector space - it uses a kernel that takes for every 2 values of that and computes a single nubmer that goes into the model.:

you can say to the extent that there are 3 way interactions they wont get shrunk that much
the kernel process hides the dimensional space
you cant say which one contribites to to the model 
nyou care about predictions and not over fitting (that's why you use cv)
you can run svm and delete one at a time to see which one contributes most 

*** Vertical profile
helena krasnov is working on calipso and looking at vertical profiles across USA, europe and israeli
we saw that in the usa as compared to israel most particles (especially during the winter months) are higher up in the vertical profile compared to israel. this maybe can explain some of the differences when calibrating on ground moistens?
**** joel
secondary particles higher up in the atmosphere
2006-proportion higher up should go down.
take a look at vertical profiles across urban areas 
Euro-satellite-UV data investigate
*** domichi grant
HEI lady at ISEE told me the grant was approved but Francesca domichi Secretary told our research authority the sub contract has been cancelled..is that right?
*** dealing with contribution of AOD- talked to brent 
Is a mixed model approach the best method to use for predicting PM2.5? we see that the contribution of AOD is minor on top of the main date predictor (not so much the case when using doy where aod adds ~ 10%). what are your thoughts on this? is there 
another approach that will allow us to evaluate the contribution of AOD in the model driven by date.

(3) Since the date clearly has the strongest effect, any other variables we add are marginly contributing to the model. are there alternative modeling approaches we should explore? we were thinking about SVM, PLS and maybe a SVM+random component?  adding spatial auto correlation?
*** TODO send xian pm monitor data 
